# -*- coding: utf-8 -*-
"""DataScienceProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lo16Iyq3meYu-n-sz7J3KHtI30gV52kH
"""

import numpy as np
import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

df=pd.read_csv("/content/Train.csv")

print(df.shape)
print(df.info())
print(df.describe())
df.head()

#  check NaN values in dataframe 
df.iloc[:,2:].isnull().values.any()

# Fill that values with mean
from sklearn.impute import SimpleImputer
imp = SimpleImputer(missing_values=np.nan, strategy='mean')
df.iloc[:,2:]=imp.fit_transform(df.iloc[:,2:])

# again check for NaN values
df.iloc[:,2:].isnull().values.any()

correlation=df.corr()
correlation['MULTIPLE_OFFENSE'].sort_values(ascending=False)  # we need only for Target variable

sn.heatmap(correlation,vmin=-1,vmax=1,cmap=sn.diverging_palette(20, 220, n=200),square=True)   # graphical representation of corrilation

"""## check the linearity with X_10"""

sn.regplot(x="X_10",y="MULTIPLE_OFFENSE",data=df)


# y is either 1 or 0  
# hence it shows classification line

"""## Let's scale the **data**"""

from sklearn.preprocessing import StandardScaler
scale=StandardScaler()
df.iloc[:,2:17]=scale.fit_transform(df.iloc[:,2:17])
print(df.describe())

from sklearn.model_selection import train_test_split
train_data,test_data=train_test_split(df.iloc[:,2:],test_size=0.2)

print(train_data['MULTIPLE_OFFENSE'].value_counts())
print(test_data['MULTIPLE_OFFENSE'].value_counts())

from sklearn.ensemble import RandomForestClassifier
# from sklearn.linear_model import LogisticRegression
model=RandomForestClassifier()   # Let use all default values
# model=LogisticRegression()  
model.fit(train_data.iloc[:,:15],train_data.iloc[:,15])

"""## Calculate the Error"""

predicted_value=model.predict(test_data.iloc[:,:15])
from sklearn.metrics import mean_squared_error
MSE=mean_squared_error(predicted_value,test_data.iloc[:,15])
print(MSE)

from sklearn.model_selection import cross_val_score
score=cross_val_score(model,test_data.iloc[:,:15],test_data.iloc[:,15],cv=10)
print("Accuracy of model =",score.mean()*100,"%")

"""## Let's made predicts"""

test_df=pd.read_csv("/content/Test.csv")

print(test_df.shape)
print(test_df.info())
print(test_df.describe())
print(test_df.head())

"""check for NaN values"""

test_df.iloc[:,2:].isnull().values.any()

#  Fill NaN values
from sklearn.impute import SimpleImputer
test_imp = SimpleImputer(missing_values=np.nan, strategy='mean')
test_df.iloc[:,2:]=test_imp.fit_transform(test_df.iloc[:,2:])

#  again check for Nan value
test_df.iloc[:,2:].isnull().values.any()

# Scale the data
from sklearn.preprocessing import StandardScaler
scale=StandardScaler()
test_df.iloc[:,2:]=scale.fit_transform(test_df.iloc[:,2:])
print(test_df.describe())

"""## Now go for prediction"""

predict_data=model.predict(test_df.iloc[:,2:])
print(len(predict_data))

"""# Now a make a CSV file and store predicted value with INCIDENT_ID"""

new_df=pd.DataFrame(test_df["INCIDENT_ID"])
new_df["MULTIPLE_OFFENSE"]=predict_data
new_df.head()

#  save into file 
new_df.to_csv("Predicted_file.csv",index=False)